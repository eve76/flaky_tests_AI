{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import classification_report, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import LinearSVC,SVR\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import Binarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = str(text).lower().strip()\n",
    "    tokens = []\n",
    "    for token in text:\n",
    "        if token not in stop_words:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    return \"\".join(tokens)\n",
    "def remove_comments(text):\n",
    "    no_comments = re.sub(r'#.*', '', text)\n",
    "    no_comments = re.sub(r'/\\*.*\\/\\*', '', no_comments)\n",
    "    no_comments = re.sub(r'\\d+','',no_comments)\n",
    "    no_comments = re.sub(r'_', ' ', no_comments)\n",
    "    no_comments = re.sub(r'[][@$%:!#~/\\\\?*\"\"()={}''<>.+-;]','', no_comments)\n",
    "    return no_comments\n",
    "\n",
    "def remove_cammel(text):\n",
    "    no_cammel = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', text)).lower().split()\n",
    "    return no_cammel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'randomForest': RandomForestClassifier(random_state=1),\n",
    "    'decisionTree': DecisionTreeClassifier(min_samples_leaf=1),\n",
    "    'naiveBayes': GaussianNB(),\n",
    "    'smo': CalibratedClassifierCV(LinearSVC(fit_intercept=False, tol=0.001, C=1, dual=False, max_iter=100000), method='sigmoid'),\n",
    "    'knn': KNeighborsClassifier(n_neighbors=1, metric='euclidean'),\n",
    "    'logisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'perceptron': CalibratedClassifierCV(Perceptron()),\n",
    "    'lda': LinearDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "def round_float(value):\n",
    "    return float(\"{:.3f}\".format(value))\n",
    "\n",
    "\n",
    "def get_time(start_time):\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "def classify_with_cv(classifiers,x, y, random_state=123, cv = None, shuffle=True, normalize=[]):\n",
    "    \n",
    "    labels = ['Flaky', 'NonFlaky']\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    scaler = Binarizer(threshold=0.0,).fit(x)\n",
    "    x_norm = scaler.transform(x)\n",
    "    \n",
    "    for key, classifier in classifiers.items():\n",
    "        if (key in normalize):\n",
    "            x = x_norm\n",
    "         \n",
    "        # classifier.fit(x_train, y_train)\n",
    "        # classifier.score(x_test, y_test)\n",
    "        score = cross_val_score(classifier, x, y, cv = cv, scoring='accuracy')\n",
    "        predict = cross_val_predict(classifier, x, y, cv=cv, method='predict')\n",
    "        # y_probs = classifier.predict_proba(x_test)[:,1]\n",
    "        \n",
    "        result = {\n",
    "                'classifier': key,\n",
    "                'f1score': f1_score(y, predict, average='weighted'),\n",
    "                'accuracy': np.mean(score),\n",
    "                'confusionMatrix': confusion_matrix(y, predict),\n",
    "                # 'execution': round_float(get_time(start_time)),\n",
    "                'classificationReport': classification_report(y, predict, output_dict=True),\n",
    "                # 'AUC': roc_auc_score(y_test, y_probs),\n",
    "                'MCC': matthews_corrcoef(y, predict),\n",
    "                \n",
    "            }\n",
    "            # results = pd.concat([results, result], ignore_index=True)\n",
    "        # print( result)\n",
    "        # print('\\n')\n",
    "        results = results._append(result, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    return results\n",
    "\n",
    "### feature importance selection\n",
    "def feature_importance(x, y):\n",
    "    \n",
    "    estimator = RandomForestClassifier(random_state=123)\n",
    "    estimator.fit(x, y)\n",
    "    importance = estimator.feature_importances_\n",
    "    \n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and drop unused columns\n",
    "\n",
    "filename = './C++_data.xlsx'\n",
    "data = pd.read_excel(filename)\n",
    "df = pd.DataFrame(data, columns=['Language', 'project name', 'test case name', 'label','test case content', 'tokens'])\n",
    "df.drop('project name', axis=1, inplace=True)\n",
    "df.drop('test case name', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# preprocessing \n",
    "\n",
    "df['test case content'] = df['test case content'].apply(lambda x: remove_comments(x))\n",
    "df['test case content'] = df['test case content'].apply(lambda x: remove_cammel(x))\n",
    "\n",
    "df['tokens'] = df['test case content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "\n",
    "tokenizer = TfidfVectorizer(analyzer='word', max_features=1500,stop_words=stop_words)\n",
    "\n",
    "    \n",
    "df.tokens = df.tokens.apply(lambda x: remove_stopwords(x))\n",
    "bow_token = tokenizer.fit_transform(df.tokens)\n",
    "\n",
    "bow_data = pd.DataFrame(bow_token.toarray(), columns=tokenizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label.copy()\n",
    "df = pd.concat([df, bow_data], axis=1)\n",
    "df.label = y\n",
    "x = df.drop(['Language', 'label', 'label', 'test case content', 'tokens'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classify_with_cv(classifiers, x, y, cv=10, normalize=['knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_excel('./C++_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 features in this project is: Index(['aaa', 'outputfloatsaved', 'outside', 'overhead', 'overlong', 'ovl',\n",
      "       'packet', 'pad', 'padding', 'parameters', 'parse', 'passes',\n",
      "       'outputfloatrunning', 'patchwork', 'peanut', 'percent', 'pipe',\n",
      "       'places', 'platform', 'player'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "top_features = feature_importance(x,y)\n",
    "print(\"The top 20 features in this project is:\", x.columns[np.argsort(top_features)[:20]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
