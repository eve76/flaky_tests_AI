{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import classification_report, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import LinearSVC,SVR\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import Binarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "def clean_words(text):\n",
    "    res = re.findall(r'\\b\\w+\\b', text)\n",
    "    return res\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = str(text).lower().strip()\n",
    "    tokens = []\n",
    "    for token in text:\n",
    "        if token not in stop_words:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    return \"\".join(tokens)\n",
    "def remove_comments(text):\n",
    "    no_comments = re.sub(r'#.*', '', text)\n",
    "    no_comments = re.sub(r'/\\*.*\\/\\*', '', no_comments)\n",
    "    no_comments = re.sub(r'\\d+','',no_comments)\n",
    "    no_comments = re.sub(r'_', ' ', no_comments)\n",
    "    return no_comments\n",
    "\n",
    "def remove_cammel(text):\n",
    "    no_cammel = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', text)).lower().split()\n",
    "    return no_cammel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'randomForest': RandomForestClassifier(random_state=1),\n",
    "    'decisionTree': DecisionTreeClassifier(min_samples_leaf=1),\n",
    "    'naiveBayes': GaussianNB(),\n",
    "    'smo': CalibratedClassifierCV(LinearSVC(fit_intercept=False, tol=0.001, C=1, dual=False, max_iter=100000), method='sigmoid'),\n",
    "    'knn': KNeighborsClassifier(n_neighbors=1, metric='euclidean'),\n",
    "    'logisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'perceptron': CalibratedClassifierCV(Perceptron()),\n",
    "    'lda': LinearDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "def round_float(value):\n",
    "    return float(\"{:.3f}\".format(value))\n",
    "\n",
    "\n",
    "def get_time(start_time):\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "def classify(x_train, x_test, y_train, y_test, classifiers, normalize=[]):\n",
    "    \n",
    "    labels = ['Flaky', 'NonFlaky']\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    comparison_values = {}\n",
    "    \n",
    "    # create a normalized version\n",
    "    train_scaler = Binarizer(threshold=0.0,).fit(x_train)\n",
    "    test_scaler = Binarizer(threshold=0.0).fit(x_test)\n",
    "    x_train_norm = train_scaler.transform(x_train)\n",
    "    x_test_norm = test_scaler.transform(x_test)\n",
    "    \n",
    "    for key, classifier in classifiers.items():\n",
    "        \n",
    "        x_train_exec = x_train \n",
    "        x_test_exec = x_test\n",
    "        y_train_exec = y_train\n",
    "        y_test_exec = y_test\n",
    "        \n",
    "        if (key in normalize):\n",
    "            x_train_exec = x_train_norm\n",
    "            x_test_exec = x_test_exec\n",
    "        \n",
    "        classifier.fit(x_train_exec, y_train)\n",
    "        classifier.score(x_test_exec, y_test)\n",
    "        \n",
    "        predict = classifier.predict(x_test_exec)\n",
    "        y_probs = classifier.predict_proba(x_test_exec)[:,1]\n",
    "        \n",
    "        # save_incorrect_classifications(x_test_exec, predict, y_test, key)\n",
    "        \n",
    "        result = {\n",
    "            'classifier': key,\n",
    "            'f1score': f1_score(y_test, predict, average='weighted'),\n",
    "            'accuracy': classifier.score(x_test_exec, y_test),\n",
    "            'confusionMatrix': confusion_matrix(y_test, predict),\n",
    "            # 'execution': round_float(get_time(start_time)),\n",
    "            'classificationReport': classification_report(y_test, predict, output_dict=True),\n",
    "            'AUC': roc_auc_score(y_test, y_probs),\n",
    "            'MCC': matthews_corrcoef(y_test, predict),\n",
    "            \n",
    "        }\n",
    "        # results = pd.concat([results, result], ignore_index=True)\n",
    "        results = results._append(result, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        # print(key, classification_report(y_test, predict, output_dict=True)['Flaky'], matthews_corrcoef(y_test, predict), roc_auc_score(y_test, y_probs), \"\\n \\n\")\n",
    "\n",
    "        # res = [key, classification_report(y_test, predict, output_dict=True)['Flaky'], matthews_corrcoef(y_test, predict), roc_auc_score(y_test, y_probs)]\n",
    "    \n",
    "        # classifications = classification_report(y_test, predict, output_dict=True)['Flaky']\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init dataset\n",
    "data = pd.read_excel('./flaky_data.xlsx')\n",
    "df = pd.DataFrame(data, columns=['Language', 'project name', 'test case name', 'label','test case content', 'tokens'])\n",
    "df.drop('project name', axis=1, inplace=True)\n",
    "df.drop('test case name', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#remove comments\n",
    "\n",
    "df['test case content'] = df['test case content'].apply(lambda x: remove_comments(x))\n",
    "df['test case content'] = df['test case content'].apply(lambda x: remove_cammel(x))\n",
    "# df['test case content'] = df['test case content'].apply(lambda x: clean_words(x))\n",
    "\n",
    "\n",
    "df['tokens'] = df['test case content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CountVectorizer(analyzer='word', max_features=1500,stop_words=stop_words)\n",
    "\n",
    "    \n",
    "df.tokens = df.tokens.apply(lambda x: remove_stopwords(x))\n",
    "bow_token = tokenizer.fit_transform(df.tokens)\n",
    "\n",
    "bow_data = pd.DataFrame(bow_token.toarray(), columns=tokenizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label.copy()\n",
    "df = pd.concat([df, bow_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_df = df[df['Language'] == 'Java']\n",
    "python_df = df[df['Language'] == 'Python']\n",
    "go_df = df[df['Language'] == 'go']\n",
    "cpp_df = df[df['Language'] == 'C++']\n",
    "js_df = df[df['Language'] == 'JS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, n):\n",
    "    java = java_df.sample(n, replace=False, random_state=123, axis=0)\n",
    "    java_y = java.iloc[:, 1:2]\n",
    "    java_x = java.drop(columns=['Language', 'label','label', 'test case content', 'tokens'])\n",
    "    \n",
    "    return java_x, java_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with java and test with others, train-test spliting 70-30\n",
    "# java = java_df.sample(800, replace=False, random_state=123, axis=0)\n",
    "# java_y = java.iloc[:, 1:2]\n",
    "# java_x = java.drop(columns=['Language', 'label','label', 'test case content', 'tokens'])\n",
    "\n",
    "java_py_x, java_py_y = sample_data(java_df, 490)      # python=210, java=490\n",
    "python_y = python_df.iloc[:, 1:2] \n",
    "python_x = python_df.drop(['Language', 'label', 'label','test case content', 'tokens'], axis=1)\n",
    "\n",
    "java_cpp_x, java_cpp_y = sample_data(java_df, 189)      # cpp=78, java=189\n",
    "cpp_y = cpp_df.iloc[:, 1:2]\n",
    "cpp_x = cpp_df.drop(['Language', 'label', 'label','test case content', 'tokens'], axis=1)\n",
    "\n",
    "java_go_x, java_go_y = sample_data(java_df, 210)      #go=90, java=210\n",
    "go_y = go_df.iloc[:, 1:2]\n",
    "go_x = go_df.drop(['Language', 'label', 'label','test case content', 'tokens'], axis=1)\n",
    "\n",
    "java_js_x, java_js_y = sample_data(java_df, 140)     #js=61, java=140\n",
    "js_y = js_df.iloc[:, 1:2]\n",
    "js_x = js_df.drop(['Language', 'label', 'label','test case content', 'tokens'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results of train on java and test on other \n",
    "py_results = classify(  java_py_x, python_x, java_py_y, python_y, classifiers, normalize=['knn']) \n",
    "cpp_results = classify(  java_cpp_x, cpp_x, java_cpp_y, cpp_y, classifiers, normalize=['knn']) \n",
    "go_results = classify(  java_go_x, go_x, java_go_y, go_y, classifiers, normalize=['knn']) \n",
    "js_results = classify(  java_js_x, js_x, java_js_y, js_y, classifiers, normalize=['knn']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on python and test on other\n",
    "py_java_x, py_java_y = sample_data(java_df, 90)    # python=210, java=90\n",
    "py_cpp_x, py_cpp_y = sample_data(cpp_df, 30)     #python=210, java=30\n",
    "py_go_x, py_go_y = sample_data(go_df, 30)    #python=210, go=30\n",
    "py_js_x, py_js_y = sample_data(js_df, 30)    #python=210, js=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_results1 = classify(  python_x, py_java_x, python_y, py_java_y,  classifiers, normalize=['knn']) \n",
    "cpp_results1 = classify(  python_x, py_cpp_x, python_y, py_cpp_y, classifiers, normalize=['knn']) \n",
    "go_results1 = classify(  python_x, py_go_x, python_y, py_go_y, classifiers, normalize=['knn']) \n",
    "js_results1 = classify(  python_x, py_js_x, python_y, py_js_y, classifiers, normalize=['knn']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on cpp and test on other\n",
    "cpp_java_x, cpp_java_y = sample_data(java_df, 33)    # cpp=78, java=33\n",
    "cpp_py_x, cpp_py_y = sample_data(python_df, 33)    #cpp=78, python=33\n",
    "cpp_go_x, cpp_go_y = sample_data(go_df, 33)    # cpp=78, go=33\n",
    "cpp_js_x, cpp_js_y = sample_data(js_df, 33)   #cpp=78, js=33\n",
    "java_results2 = classify(  cpp_x, cpp_java_x, cpp_y, cpp_java_y,  classifiers, normalize=['knn']) \n",
    "py_results2 = classify(  cpp_x, cpp_py_x, cpp_y, cpp_py_y, classifiers, normalize=['knn']) \n",
    "go_results2 = classify(  cpp_x, cpp_go_x, cpp_y, cpp_go_y, classifiers, normalize=['knn']) \n",
    "js_results2 = classify(  cpp_x, cpp_js_x, cpp_y, cpp_js_y, classifiers, normalize=['knn']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on go and test on other\n",
    "go_java_x, go_java_y = sample_data(java_df, 39)    # go=90, java=39\n",
    "go_py_x, go_py_y = sample_data(python_df, 39)    #go=90, python=39\n",
    "go_cpp_x, go_cpp_y = sample_data(cpp_df, 39)    # go=90, cpp=39\n",
    "go_js_x, go_js_y = sample_data(js_df, 39)   #go=90, js=39\n",
    "java_results3 = classify(  go_x, go_java_x, go_y, go_java_y,  classifiers, normalize=['knn']) \n",
    "py_results3 = classify(  go_x, go_py_x, go_y, go_py_y, classifiers, normalize=['knn']) \n",
    "cpp_results3 = classify(  go_x, go_js_x, go_y, go_js_y, classifiers, normalize=['knn']) \n",
    "js_results3 = classify(  go_x, go_js_x, go_y, go_js_y, classifiers, normalize=['knn']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on js and test on other\n",
    "js_java_x, js_java_y = sample_data(java_df, 27)    # js=61, java=27\n",
    "js_py_x, js_py_y = sample_data(python_df, 27)    # js=61, python=27\n",
    "js_cpp_x, js_cpp_y = sample_data(cpp_df, 27)    # js=61, cpp=27\n",
    "js_go_x, js_go_y = sample_data(go_df, 27)   # js=61, go=27\n",
    "java_results4 = classify(  js_x, js_java_x, js_y, js_java_y,  classifiers, normalize=['knn']) \n",
    "py_results4 = classify(  js_x, js_py_x, js_y, js_py_y, classifiers, normalize=['knn']) \n",
    "cpp_results4 = classify(  js_x, js_cpp_x, js_y, js_cpp_y, classifiers, normalize=['knn']) \n",
    "go_results4 = classify(  js_x, js_go_x, js_y, js_go_y, classifiers, normalize=['knn']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_test_results = pd.DataFrame()\n",
    "cross_test_results = pd.concat([py_results, cpp_results, go_results, js_results, java_results1, cpp_results1, go_results1, js_results1,\n",
    "                                java_results2, py_results2, go_results2, js_results2, java_results3, py_results3, cpp_results3, js_results3,\n",
    "                                java_results4, py_results4, cpp_results4, go_results4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_test_results.to_excel('./cross_test_results.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
